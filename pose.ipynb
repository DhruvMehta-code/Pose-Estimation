{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94dd11e4-2f8f-44aa-9129-dc9d9dcd294f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import subprocess\n",
    "mp_selfie_segmentation = mp.solutions.selfie_segmentation\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_pose = mp.solutions.pose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6da40530-f7f3-4fe1-81d3-c200926011a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "General configuration for OpenCV 4.8.0 =====================================\n",
      "  Version control:               4.8.0\n",
      "\n",
      "  Platform:\n",
      "    Timestamp:                   2023-06-30T11:22:01Z\n",
      "    Host:                        Windows 10.0.17763 AMD64\n",
      "    CMake:                       3.24.2\n",
      "    CMake generator:             Visual Studio 14 2015\n",
      "    CMake build tool:            MSBuild.exe\n",
      "    MSVC:                        1900\n",
      "    Configuration:               Debug Release\n",
      "\n",
      "  CPU/HW features:\n",
      "    Baseline:                    SSE SSE2 SSE3\n",
      "      requested:                 SSE3\n",
      "    Dispatched code generation:  SSE4_1 SSE4_2 FP16 AVX AVX2\n",
      "      requested:                 SSE4_1 SSE4_2 AVX FP16 AVX2 AVX512_SKX\n",
      "      SSE4_1 (16 files):         + SSSE3 SSE4_1\n",
      "      SSE4_2 (1 files):          + SSSE3 SSE4_1 POPCNT SSE4_2\n",
      "      FP16 (0 files):            + SSSE3 SSE4_1 POPCNT SSE4_2 FP16 AVX\n",
      "      AVX (7 files):             + SSSE3 SSE4_1 POPCNT SSE4_2 AVX\n",
      "      AVX2 (35 files):           + SSSE3 SSE4_1 POPCNT SSE4_2 FP16 FMA3 AVX AVX2\n",
      "\n",
      "  C/C++:\n",
      "    Built as dynamic libs?:      NO\n",
      "    C++ standard:                11\n",
      "    C++ Compiler:                C:/Program Files (x86)/Microsoft Visual Studio 14.0/VC/bin/x86_amd64/cl.exe  (ver 19.0.24247.2)\n",
      "    C++ flags (Release):         /DWIN32 /D_WINDOWS /W4 /GR  /D _CRT_SECURE_NO_DEPRECATE /D _CRT_NONSTDC_NO_DEPRECATE /D _SCL_SECURE_NO_WARNINGS /Gy /bigobj /Oi  /fp:precise     /EHa /wd4127 /wd4251 /wd4324 /wd4275 /wd4512 /wd4589 /wd4819 /MP  /MT /O2 /Ob2 /DNDEBUG \n",
      "    C++ flags (Debug):           /DWIN32 /D_WINDOWS /W4 /GR  /D _CRT_SECURE_NO_DEPRECATE /D _CRT_NONSTDC_NO_DEPRECATE /D _SCL_SECURE_NO_WARNINGS /Gy /bigobj /Oi  /fp:precise     /EHa /wd4127 /wd4251 /wd4324 /wd4275 /wd4512 /wd4589 /wd4819 /MP  /MTd /Zi /Ob0 /Od /RTC1 \n",
      "    C Compiler:                  C:/Program Files (x86)/Microsoft Visual Studio 14.0/VC/bin/x86_amd64/cl.exe\n",
      "    C flags (Release):           /DWIN32 /D_WINDOWS /W3  /D _CRT_SECURE_NO_DEPRECATE /D _CRT_NONSTDC_NO_DEPRECATE /D _SCL_SECURE_NO_WARNINGS /Gy /bigobj /Oi  /fp:precise     /MP   /MT /O2 /Ob2 /DNDEBUG \n",
      "    C flags (Debug):             /DWIN32 /D_WINDOWS /W3  /D _CRT_SECURE_NO_DEPRECATE /D _CRT_NONSTDC_NO_DEPRECATE /D _SCL_SECURE_NO_WARNINGS /Gy /bigobj /Oi  /fp:precise     /MP /MTd /Zi /Ob0 /Od /RTC1 \n",
      "    Linker flags (Release):      /machine:x64  /NODEFAULTLIB:atlthunk.lib /INCREMENTAL:NO  /NODEFAULTLIB:libcmtd.lib /NODEFAULTLIB:libcpmtd.lib /NODEFAULTLIB:msvcrtd.lib\n",
      "    Linker flags (Debug):        /machine:x64  /NODEFAULTLIB:atlthunk.lib /debug /INCREMENTAL  /NODEFAULTLIB:libcmt.lib /NODEFAULTLIB:libcpmt.lib /NODEFAULTLIB:msvcrt.lib\n",
      "    ccache:                      NO\n",
      "    Precompiled headers:         YES\n",
      "    Extra dependencies:          wsock32 comctl32 gdi32 ole32 setupapi ws2_32\n",
      "    3rdparty dependencies:       libprotobuf ade ittnotify libjpeg-turbo libwebp libpng libtiff libopenjp2 IlmImf zlib quirc ippiw ippicv\n",
      "\n",
      "  OpenCV modules:\n",
      "    To be built:                 calib3d core dnn features2d flann gapi highgui imgcodecs imgproc ml objdetect photo python3 stitching video videoio\n",
      "    Disabled:                    java world\n",
      "    Disabled by dependency:      -\n",
      "    Unavailable:                 python2 ts\n",
      "    Applications:                -\n",
      "    Documentation:               NO\n",
      "    Non-free algorithms:         NO\n",
      "\n",
      "  Windows RT support:            NO\n",
      "\n",
      "  GUI:                           WIN32UI\n",
      "    Win32 UI:                    YES\n",
      "    VTK support:                 NO\n",
      "\n",
      "  Media I/O: \n",
      "    ZLib:                        build (ver 1.2.13)\n",
      "    JPEG:                        build-libjpeg-turbo (ver 2.1.3-62)\n",
      "      SIMD Support Request:      YES\n",
      "      SIMD Support:              NO\n",
      "    WEBP:                        build (ver encoder: 0x020f)\n",
      "    PNG:                         build (ver 1.6.37)\n",
      "    TIFF:                        build (ver 42 - 4.2.0)\n",
      "    JPEG 2000:                   build (ver 2.5.0)\n",
      "    OpenEXR:                     build (ver 2.3.0)\n",
      "    HDR:                         YES\n",
      "    SUNRASTER:                   YES\n",
      "    PXM:                         YES\n",
      "    PFM:                         YES\n",
      "\n",
      "  Video I/O:\n",
      "    DC1394:                      NO\n",
      "    FFMPEG:                      YES (prebuilt binaries)\n",
      "      avcodec:                   YES (58.134.100)\n",
      "      avformat:                  YES (58.76.100)\n",
      "      avutil:                    YES (56.70.100)\n",
      "      swscale:                   YES (5.9.100)\n",
      "      avresample:                YES (4.0.0)\n",
      "    GStreamer:                   NO\n",
      "    DirectShow:                  YES\n",
      "    Media Foundation:            YES\n",
      "      DXVA:                      YES\n",
      "\n",
      "  Parallel framework:            Concurrency\n",
      "\n",
      "  Trace:                         YES (with Intel ITT)\n",
      "\n",
      "  Other third-party libraries:\n",
      "    Intel IPP:                   2021.8 [2021.8.0]\n",
      "           at:                   D:/a/opencv-python/opencv-python/_skbuild/win-amd64-3.7/cmake-build/3rdparty/ippicv/ippicv_win/icv\n",
      "    Intel IPP IW:                sources (2021.8.0)\n",
      "              at:                D:/a/opencv-python/opencv-python/_skbuild/win-amd64-3.7/cmake-build/3rdparty/ippicv/ippicv_win/iw\n",
      "    Lapack:                      NO\n",
      "    Eigen:                       NO\n",
      "    Custom HAL:                  NO\n",
      "    Protobuf:                    build (3.19.1)\n",
      "    Flatbuffers:                 builtin/3rdparty (23.5.9)\n",
      "\n",
      "  OpenCL:                        YES (NVD3D11)\n",
      "    Include path:                D:/a/opencv-python/opencv-python/opencv/3rdparty/include/opencl/1.2\n",
      "    Link libraries:              Dynamic load\n",
      "\n",
      "  Python 3:\n",
      "    Interpreter:                 C:/hostedtoolcache/windows/Python/3.7.9/x64/python.exe (ver 3.7.9)\n",
      "    Libraries:                   C:/hostedtoolcache/windows/Python/3.7.9/x64/libs/python37.lib (ver 3.7.9)\n",
      "    numpy:                       C:/hostedtoolcache/windows/Python/3.7.9/x64/lib/site-packages/numpy/core/include (ver 1.17.0)\n",
      "    install path:                python/cv2/python-3\n",
      "\n",
      "  Python (for build):            C:\\hostedtoolcache\\windows\\Python\\3.7.9\\x64\\python.exe\n",
      "\n",
      "  Java:                          \n",
      "    ant:                         NO\n",
      "    Java:                        YES (ver 1.8.0.372)\n",
      "    JNI:                         C:/hostedtoolcache/windows/Java_Temurin-Hotspot_jdk/8.0.372-7/x64/include C:/hostedtoolcache/windows/Java_Temurin-Hotspot_jdk/8.0.372-7/x64/include/win32 C:/hostedtoolcache/windows/Java_Temurin-Hotspot_jdk/8.0.372-7/x64/include\n",
      "    Java wrappers:               NO\n",
      "    Java tests:                  NO\n",
      "\n",
      "  Install to:                    D:/a/opencv-python/opencv-python/_skbuild/win-amd64-3.7/cmake-install\n",
      "-----------------------------------------------------------------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(cv2.getBuildInformation())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51264061-1445-4064-b143-ba9872a40088",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_directory = \"E:\\\\course_work\\\\Dissertation\\\\back_001\"\n",
    "\n",
    "all_files_in_directory = os.listdir(video_directory)\n",
    "\n",
    "video_files = [file for file in all_files_in_directory if file.endswith(('.mkv'))]\n",
    "\n",
    "videos = []\n",
    "\n",
    "for video_file in video_files:\n",
    "    video_file_path = os.path.join(video_directory, video_file)\n",
    "    output_file_path = os.path.splitext(video_file_path)[0] + '.mp4'\n",
    "    subprocess.run(['ffmpeg', '-i', video_file_path, output_file_path])\n",
    "    videos.append(output_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "43e26167-462d-4fce-bc23-0a9035580fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "  \n",
    "output_folder = \"E:\\\\course_work\\\\Dissertation\\\\pose_estim\" \n",
    "output_extension = \".mp4\"\n",
    "\n",
    "# Set the video writer parameters\n",
    "fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")  # Specify the video codec (e.g., \"mp4v\" for MP4)\n",
    "\n",
    "frame_size = (1280, 720)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df2a0cbb-015a-4971-8e75-d547efd79b27",
   "metadata": {},
   "source": [
    "# Estimation Keypoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "463790d4-0d0e-4114-8001-4301cbd7fb73",
   "metadata": {},
   "source": [
    "<img src=\"https://www.mdpi.com/applsci/applsci-13-02700/article_deploy/html/images/applsci-13-02700-g001.png\" style=\"height=200px\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3db41026-8133-4c9b-9b09-9bd30d369304",
   "metadata": {},
   "source": [
    "# Jumping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "63bf9d75-022e-4119-8646-74d3f87d1cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_vertical_displacement(a, b):\n",
    "    \"\"\"Calculate the vertical displacement between points a and b\"\"\"\n",
    "    return b - a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a5963b6-5c0a-4c2b-b91a-6d30248ea873",
   "metadata": {},
   "source": [
    "# Squating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6b313bce-61d9-479a-85f7-3c171140ec16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_angle(a, b, c):\n",
    "    \"\"\"Calculate the angle between points a, b, and c\"\"\"\n",
    "    ba = a - b\n",
    "    bc = c - b\n",
    "\n",
    "    cosine_angle = np.dot(ba, bc) / (np.linalg.norm(ba) * np.linalg.norm(bc))\n",
    "    #cosine_angle = np.clip(cosine_angle, -1, 1)\n",
    "    angle = np.arccos(cosine_angle)\n",
    "    \n",
    "    return np.degrees(angle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8e667552-407c-44c7-8849-8ef1540e0ecf",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Squat detected in video: E:\\course_work\\Dissertation\\back_001\\back_001_m01_20230224094505.mp4\n",
      "Squat detected in video: E:\\course_work\\Dissertation\\back_001\\back_001_m01_20230224094600.mp4\n",
      "Squat detected in video: E:\\course_work\\Dissertation\\back_001\\back_001_m01_20230224094626.mp4\n",
      "Squat detected in video: E:\\course_work\\Dissertation\\back_001\\back_001_m01_20230224094649.mp4\n",
      "Squat detected in video: E:\\course_work\\Dissertation\\back_001\\back_001_m01_20230224094705.mp4\n",
      "Squat detected in video: E:\\course_work\\Dissertation\\back_001\\back_001_m01_20230224094722.mp4\n",
      "Squat detected in video: E:\\course_work\\Dissertation\\back_001\\back_001_m01_20230224094739.mp4\n",
      "Squat detected in video: E:\\course_work\\Dissertation\\back_001\\back_001_m01_20230224094754.mp4\n",
      "Squat detected in video: E:\\course_work\\Dissertation\\back_001\\back_001_m01_20230224094811.mp4\n",
      "Squat detected in video: E:\\course_work\\Dissertation\\back_001\\back_001_m01_20230224094826.mp4\n",
      "Squat detected in video: E:\\course_work\\Dissertation\\back_001\\back_001_m01_20230224094843.mp4\n",
      "Jump detected in video: E:\\course_work\\Dissertation\\back_001\\back_001_m02_20230224094942.mp4\n",
      "Jump detected in video: E:\\course_work\\Dissertation\\back_001\\back_001_m02_20230224095019.mp4\n",
      "Jump detected in video: E:\\course_work\\Dissertation\\back_001\\back_001_m02_20230224095040.mp4\n",
      "Jump detected in video: E:\\course_work\\Dissertation\\back_001\\back_001_m02_20230224095059.mp4\n",
      "Jump detected in video: E:\\course_work\\Dissertation\\back_001\\back_001_m02_20230224095121.mp4\n",
      "Jump detected in video: E:\\course_work\\Dissertation\\back_001\\back_001_m02_20230224095141.mp4\n",
      "Jump detected in video: E:\\course_work\\Dissertation\\back_001\\back_001_m02_20230224095200.mp4\n",
      "Jump detected in video: E:\\course_work\\Dissertation\\back_001\\back_001_m02_20230224095218.mp4\n",
      "Jump detected in video: E:\\course_work\\Dissertation\\back_001\\back_001_m02_20230224095236.mp4\n",
      "Squat detected in video: E:\\course_work\\Dissertation\\back_001\\back_001_m02_20230224095254.mp4\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "with mp_pose.Pose(min_detection_confidence=0.8 , min_tracking_confidence=0.8) as pose,mp_selfie_segmentation.SelfieSegmentation(model_selection=0) as selfie_segmentation:\n",
    "    for vid in videos:\n",
    "        video = cv2.VideoCapture(vid)\n",
    "        total_frames = int(video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        squat_detected = False\n",
    "        jump_detected = False\n",
    "        baseline = None\n",
    "        jump_threshold = 0.015\n",
    "        filename = os.path.splitext(os.path.basename(vid))[0]\n",
    "        output_path = os.path.join(output_folder, filename + output_extension)\n",
    "        original_fps = video.get(cv2.CAP_PROP_FPS)\n",
    "        original_frame_size = (\n",
    "            int(video.get(cv2.CAP_PROP_FRAME_WIDTH)),\n",
    "            int(video.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "        )\n",
    "        video_writer = cv2.VideoWriter(output_path, fourcc, original_fps, frame_size)\n",
    "        while True:\n",
    "            ret,frame = video.read()\n",
    "            if not ret:\n",
    "                break\n",
    "\n",
    "            resized_frame = cv2.resize(frame, frame_size)\n",
    "            image = cv2.cvtColor(resized_frame,cv2.COLOR_BGR2RGB)\n",
    "            image.flags.writeable = False\n",
    "            results = pose.process(image)\n",
    "            segmentation_results = selfie_segmentation.process(image)\n",
    "            image.flags.writeable = True\n",
    "            \n",
    "            if results.pose_landmarks:\n",
    "                landmarks = results.pose_landmarks.landmark\n",
    "\n",
    "                # Squating\n",
    "                # right_hip = np.array([landmarks[mp_pose.PoseLandmark.RIGHT_HIP].x, landmarks[mp_pose.PoseLandmark.RIGHT_HIP].y])\n",
    "                # left_hip = np.array([landmarks[mp_pose.PoseLandmark.LEFT_HIP].x, landmarks[mp_pose.PoseLandmark.LEFT_HIP].y])\n",
    "                # right_knee = np.array([landmarks[mp_pose.PoseLandmark.RIGHT_KNEE].x, landmarks[mp_pose.PoseLandmark.RIGHT_KNEE].y])\n",
    "                # left_knee = np.array([landmarks[mp_pose.PoseLandmark.LEFT_KNEE].x, landmarks[mp_pose.PoseLandmark.LEFT_KNEE].y])\n",
    "                # right_shoulder = np.array([landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER].x, landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER].y])\n",
    "                # left_shoulder = np.array([landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER].x, landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER].y])\n",
    "                # right_elbow = np.array([landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW].x, landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW].y])\n",
    "                # left_elbow = np.array([landmarks[mp_pose.PoseLandmark.LEFT_ELBOW].x, landmarks[mp_pose.PoseLandmark.LEFT_ELBOW].y])\n",
    "                # right_heel = np.array([landmarks[mp_pose.PoseLandmark.RIGHT_HEEL].x, landmarks[mp_pose.PoseLandmark.RIGHT_HEEL].y])\n",
    "                # left_heel = np.array([landmarks[mp_pose.PoseLandmark.LEFT_HEEL].x, landmarks[mp_pose.PoseLandmark.LEFT_HEEL].y])\n",
    "                \n",
    "                \n",
    "                # if hip_knee_angle < 90 and shoulder_hip_angle < 130 and shoulder_angle < 70 and shoulder_angle > 60 and elbow_angle > 90 and elbow_angle < 100 :# Adjust the threshold values as needed\n",
    "                #     if right_heel[1] >= right_knee[1] and left_heel[1] >= left_knee[1]:\n",
    "                #         squat_detected = True\n",
    "\n",
    "                right_hip = np.array([landmarks[mp_pose.PoseLandmark.RIGHT_HIP].x, landmarks[mp_pose.PoseLandmark.RIGHT_HIP].y])\n",
    "                right_knee = np.array([landmarks[mp_pose.PoseLandmark.RIGHT_KNEE].x, landmarks[mp_pose.PoseLandmark.RIGHT_KNEE].y])\n",
    "                left_knee = np.array([landmarks[mp_pose.PoseLandmark.LEFT_KNEE].x, landmarks[mp_pose.PoseLandmark.LEFT_KNEE].y])\n",
    "                right_shoulder = np.array([landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER].x, landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER].y])\n",
    "                left_shoulder = np.array([landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER].x, landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER].y])\n",
    "                right_hip = np.array([landmarks[mp_pose.PoseLandmark.RIGHT_HIP].x, landmarks[mp_pose.PoseLandmark.RIGHT_HIP].y])\n",
    "                right_elbow = np.array([landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW].x, landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW].y])\n",
    "                right_wrist = np.array([landmarks[mp_pose.PoseLandmark.RIGHT_WRIST].x, landmarks[mp_pose.PoseLandmark.RIGHT_WRIST].y])\n",
    "                \n",
    "                # Calculate angles\n",
    "                elbow_angle = calculate_angle(right_shoulder, right_elbow, right_wrist)\n",
    "                hip_knee_angle = calculate_angle(right_hip, right_knee, left_knee)\n",
    "                shoulder_hip_angle = calculate_angle(right_shoulder, right_hip, left_hip)\n",
    "                shoulder_angle = calculate_angle(right_shoulder, left_shoulder, right_hip)\n",
    "                \n",
    "                # Detect squats\n",
    "                squat_condition1 = hip_knee_angle < 110\n",
    "                squat_condition2 = shoulder_hip_angle < 130\n",
    "                squat_condition3 = shoulder_angle < 70\n",
    "                squat_condition4 = elbow_angle > 90\n",
    "                squat_condition5 = landmarks[mp_pose.PoseLandmark.RIGHT_HEEL].y >= landmarks[mp_pose.PoseLandmark.RIGHT_KNEE].y\n",
    "                squat_condition6 = landmarks[mp_pose.PoseLandmark.LEFT_HEEL].y >= landmarks[mp_pose.PoseLandmark.LEFT_KNEE].y\n",
    "                if squat_condition1 and squat_condition2 and squat_condition3 and squat_condition4 and squat_condition5 and squat_condition6:  # Ensuring heels are grounded\n",
    "                    squat_detected = True\n",
    "                \n",
    "                # Detect jumps\n",
    "                # jump_condition1 = hip_knee_angle < 150\n",
    "                # jump_condition2 = shoulder_hip_angle < 180\n",
    "                # jump_condition3 = shoulder_angle < 90\n",
    "                # jump_condition4 = elbow_angle > 80\n",
    "                # jump_condition5 = landmarks[mp_pose.PoseLandmark.RIGHT_HEEL].y < landmarks[mp_pose.PoseLandmark.RIGHT_KNEE].y\n",
    "                # jump_condition6 = landmarks[mp_pose.PoseLandmark.LEFT_HEEL].y < landmarks[mp_pose.PoseLandmark.LEFT_KNEE].y\n",
    "                # if jump_condition1 and jump_condition2 and jump_condition3 and jump_condition4 and jump_condition5 and jump_condition6 and not squat_detected:  \n",
    "                #     # Only detect a jump if a squat hasn't been detected in the same frame\n",
    "                #     jump_detected = True\n",
    "\n",
    "\n",
    "                # Jumping\n",
    "\n",
    "                hip_y = (landmarks[27].y + landmarks[28].y) / 2\n",
    "    \n",
    "                if baseline is None:\n",
    "                    baseline = hip_y\n",
    "                else:\n",
    "                    # Calculate the distance of the hips from the baseline\n",
    "                    hip_distance = calculate_vertical_displacement(baseline,hip_y)\n",
    "\n",
    "                    if hip_distance > jump_threshold :\n",
    "                        jump_detected = True\n",
    "                    baseline = hip_y\n",
    "\n",
    "                mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS)\n",
    "\n",
    "                #Frame Normalization\n",
    "                landmarks_array = np.array([(lmk.x, lmk.y, lmk.z) for lmk in landmarks])\n",
    "                # Normalize the landmarks\n",
    "                mean = np.mean(landmarks_array, axis=0)\n",
    "                std = np.std(landmarks_array, axis=0)\n",
    "                normalized_landmarks = (landmarks_array - mean) / std\n",
    "\n",
    "            condition = np.stack((segmentation_results.segmentation_mask,) * 3, axis=-1) > 0.1\n",
    "            # this two will blurred background \n",
    "            blurred_image = cv2.GaussianBlur(image, (99, 99), 30)\n",
    "            output_image = np.where(condition, image, blurred_image)\n",
    "\n",
    "            # this below lines change background to green color\n",
    "            # background_color = np.zeros_like(image)\n",
    "            # background_color[:] = [0, 255, 0]  # Green in BGR\n",
    "            # output_image = np.where(condition, image, background_color)\n",
    "            \n",
    "\n",
    "            video_writer.write(output_image)\n",
    "        if squat_detected and not jump_detected:\n",
    "            print(f\"Squat detected in video: {vid}\")\n",
    "        if jump_detected and squat_detected:\n",
    "            print(f\"Jump detected in video: {vid}\")\n",
    "        # else:\n",
    "        #     print(f\"nothing detected in video: {vid}\")\n",
    "        video.release()\n",
    "        video_writer.release()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2971237c-fe86-49f1-bf96-eff5ee8ccd25",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "351c56bb-8d23-4401-93da-951eeaef7dca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
